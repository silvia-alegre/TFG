
@book{murphy2022probabilistic,
  title={Probabilistic Machine Learning: An Introduction},
  author={Murphy, Kevin P.},
  year={2022},
  publisher={The MIT Press},
  address={Cambridge, Massachusetts; London, England}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% APRENDIZAJE AUTOM√ÅTICO %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@Inbook{samuelCheckers,
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  title = {Samuel's Checkers Player},
  bookTitle = {Encyclopedia of Machine Learning},
  year = {2010},
  publisher = {Springer US},
  address = {Boston, MA},
  pages = {881--881},
  isbn = {978-0-387-30164-8},
  url = {\url{https://doi.org/10.1007/978-0-387-30164-8_740}},
}


@book{mitchell1997mcgraw,
  title={Machine Learningl},
  author={Mitchell, Tom},
  publisher={McGraw-Hil},
  pages={154--200},
  year={1997}
}

@book{mirtaheri2022machine,
  title={Machine Learning},
  author={Mirtaheri, Seyedeh Leili and Shahbazian, Reza},
  year={2022},
  publisher={CRC Press},
}

@book{alma997066713303706,
author = {Sowmya V. B. and Majumder, Bodhisattwa and Gupta, Anuj and Surana, Harshit},
address = {Sebastopol, CA},
booktitle = {Practical natural language processing : a comprehensive guide to building real-world NLP systems},
edition = {First edition.},
isbn = {1-4920-5402-X},
keywords = {Application software -- Development},
language = {eng},
publisher = {O'Reilly Media},
title = {Practical natural language processing : a comprehensive guide to building real-world NLP systems },
year = {2020 - 2020},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% REDES NEURONALES %%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{mcculloch1943logical,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={Bulletin of Mathematical Biophysics},
  volume={5},
  number={4},
  pages={115--133},
  year={1943},
  publisher={Springer},
  doi={10.1007/BF02478259}
}

@book{jurafsky2023speech,
  title={Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition},
  author={Jurafsky, Daniel and Martin, James H.},
  edition={Third Edition draft},
  publisher={Stanford University and University of Colorado at Boulder},
  year={2023},
  note={Draft version}
}

@misc{sutskever2014sequencesequencelearningneural,
      title={Sequence to Sequence Learning with Neural Networks}, 
      author={Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
      year={2014},
      eprint={1409.3215},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1409.3215}, 
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% TRANSFORMERS %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@article{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@INPROCEEDINGS{multiheaddotproduct,
  author={Bilonoh, Bohdan and Mashtalir, Sergii},
  booktitle={2020 IEEE Third International Conference on Data Stream Mining \& Processing (DSMP)}, 
  title={Parallel multi-head dot product attention for video summarization}, 
  year={2020},
  volume={},
  number={},
  pages={158-162},
  keywords={Computational modeling;Computer architecture;Training;YouTube;Natural language processing;Adaptation models;Task analysis;video summarization;sequence to sequence;self-attention;Transformer},
  doi={10.1109/DSMP47368.2020.9204059}}

@misc{cordonnier2021multiheadattentioncollaborateinstead,
      title={Multi-Head Attention: Collaborate Instead of Concatenate}, 
      author={Jean-Baptiste Cordonnier and Andreas Loukas and Martin Jaggi},
      year={2021},
      eprint={2006.16362},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.16362}, 
}

@misc{ba2016layernormalization,
      title={Layer Normalization}, 
      author={Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
      year={2016},
      eprint={1607.06450},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1607.06450}, 
}

@misc{sriram2017coldfusiontrainingseq2seq,
      title={Cold Fusion: Training Seq2Seq Models Together with Language Models}, 
      author={Anuroop Sriram and Heewoo Jun and Sanjeev Satheesh and Adam Coates},
      year={2017},
      eprint={1708.06426},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1708.06426}, 
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% LANGUAGE MODELS %%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{burtsev2023working,
  title={The Working Limitations of Large Language Models},
  author={Burtsev, Mikhail and Reeves, Martin and Job, Adam},
  journal={MIT Sloan Management Review},
  year={2023},
  month={November},
  pages={7},
}

@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@misc{dai2019transformerxlattentivelanguagemodels,
      title={Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context}, 
      author={Zihang Dai and Zhilin Yang and Yiming Yang and Jaime Carbonell and Quoc V. Le and Ruslan Salakhutdinov},
      year={2019},
      eprint={1901.02860},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1901.02860}, 
}

@misc{gu2017trainablegreedydecodingneural,
      title={Trainable Greedy Decoding for Neural Machine Translation}, 
      author={Jiatao Gu and Kyunghyun Cho and Victor O. K. Li},
      year={2017},
      eprint={1702.02429},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1702.02429}, 
}

@misc{nadeem2020systematiccharacterizationsamplingalgorithms,
      title={A Systematic Characterization of Sampling Algorithms for Open-ended Language Generation}, 
      author={Moin Nadeem and Tianxing He and Kyunghyun Cho and James Glass},
      year={2020},
      eprint={2009.07243},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2009.07243}, 
}

@misc{holtzman2020curiouscaseneuraltext,
      title={The Curious Case of Neural Text Degeneration}, 
      author={Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
      year={2020},
      eprint={1904.09751},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1904.09751}, 
}

%lora
@article{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}



